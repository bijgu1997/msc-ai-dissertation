{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets transformers scikit-learn pandas torch simpletransformers scipy wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_CSV_PATH = '/home/nli/data'\n",
    "OUTPUT_PATH = '/home/nli/outputs'\n",
    "\n",
    "MODEL_SNLI_FULL = '/home/nli/trained_models/snli_full/'\n",
    "MODEL_SNLI_LITE = '/home/nli/trained_models/snli_subset/'\n",
    "MODEL_MNLI_LITE = '/home/nli/trained_models/mnli_subset/'\n",
    "MODEL_COMBONLI = '/home/nli/trained_models/combo_nli_new_subset/'\n",
    "MODEL_BASELINE = 'MLRS/BERTu'\n",
    "\n",
    "MNLI_EVAL = '/home/nli/data/unique_mnli_eval.csv'\n",
    "SNLI_EVAL = '/home/nli/data/unique_snli_eval.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import (\n",
    "    ClassificationModel, ClassificationArgs\n",
    ")\n",
    "import pandas as pd\n",
    "import logging\n",
    "import torch\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "# cuda_available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_num(label):\n",
    "  if label == 'entailment':\n",
    "    return 0\n",
    "  elif label == 'contradiction':\n",
    "    return 2\n",
    "  else:\n",
    "    return 1\n",
    "\n",
    "def map_to_label(num):\n",
    "  if num == 0:\n",
    "    return \"entailment\"\n",
    "  elif num == 2:\n",
    "    return \"contradiction\"\n",
    "  else:\n",
    "    return \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df(df):\n",
    "    cols_to_drop = ['Unnamed: 0.1', 'Unnamed: 0']\n",
    "    df.drop(columns=cols_to_drop, axis=1, inplace=True)\n",
    "    df.columns = [\"text_a\",\"text_b\",\"labels\"]\n",
    "    df_labels = [map_to_num(x) for x in df['labels'].to_list()]\n",
    "    df['labels'] = df_labels\n",
    "    df[\"labels\"] = df[\"labels\"].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_eval = format_df(pd.read_csv(MNLI_EVAL, delimiter=\";\", encoding='utf-8'))\n",
    "snli_eval = format_df(pd.read_csv(SNLI_EVAL, delimiter=\";\", encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "\n",
    "def f1_multiclass(labels, preds):\n",
    "    return f1_score(labels, preds, average = 'macro')\n",
    "\n",
    "def recall_multiclass(labels, preds):\n",
    "    return recall_score(labels, preds, average = 'macro')\n",
    "\n",
    "def precision_multiclass(labels, preds):\n",
    "    return precision_score(labels, preds, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_full_model = ClassificationModel('bert', MODEL_SNLI_FULL)\n",
    "snli_lite_model = ClassificationModel('bert', MODEL_SNLI_LITE)\n",
    "mnli_lite_model = ClassificationModel('bert', MODEL_MNLI_LITE)\n",
    "combonli_model = ClassificationModel('bert', MODEL_COMBONLI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = ClassificationArgs()\n",
    "model_args.num_train_epochs = 4\n",
    "model_args.learning_rate = 5e-5\n",
    "model_args.train_batch_size = 8\n",
    "model_args.gradient_accumulation_steps = 4\n",
    "model_args.fp16 = True\n",
    "model_args.use_multiprocessing = False\n",
    "model_args.use_multiprocessing_for_evaluation = False\n",
    "model_args.use_multiprocessed_decoding = False\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.reprocess_input_data = True\n",
    "model_args.use_multiprocessing=False\n",
    "model_args.wandb_project = 'dissertation'\n",
    "# model_args.manual_seed = 4\n",
    "model_args.max_seq_length = 512\n",
    "model_args.evaluate_during_training = True\n",
    "model_args.evaluate_during_training_steps = 50000\n",
    "model_args.evaluate_during_training_verbose = True\n",
    "model_args.save_eval_checkpoints = False\n",
    "model_args.save_steps = 250000\n",
    "model_args.output_dir = '/home/nli/outputs'\n",
    "baseline_model = ClassificationModel('bert',\"MLRS/BERTu\", num_labels=3, args=model_args, use_cuda=cuda_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_name, dataset, model, eval_data):\n",
    "    result, model_outputs, wrong_predictions = model.eval_model(\n",
    "        eval_data, precision=precision_multiclass, f1 = f1_multiclass, recall=recall_multiclass,  acc=accuracy_score\n",
    "    )\n",
    "    df = pd.DataFrame.from_dict([result])\n",
    "    df['model'] = model_name\n",
    "    df['dataset'] = dataset\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list.append(evaluate_model(\"SNLI Full\",\"SNLI Dataset\", snli_full_model, snli_eval))\n",
    "df_list.append(evaluate_model(\"SNLI Full\",\"MNLI Dataset\", snli_full_model, mnli_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list.append(evaluate_model(\"SNLI Lite\",\"SNLI Dataset\", snli_lite_model, snli_eval))\n",
    "df_list.append(evaluate_model(\"SNLI Lite\",\"MNLI Dataset\", snli_lite_model, mnli_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list.append(evaluate_model(\"MNLI Lite\",\"SNLI Dataset\", mnli_lite_model, snli_eval))\n",
    "df_list.append(evaluate_model(\"MNLI Lite\",\"MNLI Dataset\", mnli_lite_model, mnli_eval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list.append(evaluate_model(\"ComboNLI\" ,\"SNLI Dataset\", combonli_model , snli_eval))\n",
    "df_list.append(evaluate_model(\"ComboNLI\" ,\"MNLI Dataset\", combonli_model , mnli_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list.append(evaluate_model(\"BERTu\"    ,\"SNLI Dataset\", baseline_model , snli_eval))\n",
    "df_list.append(evaluate_model(\"BERTu\"    ,\"MNLI Dataset\", baseline_model , mnli_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = pd.concat(df_list)\n",
    "df_grouped.to_csv('/home/nli/final_test_results.csv', encoding='utf-8',sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
