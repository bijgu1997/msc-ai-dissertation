{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctranslate2\n",
    "import sentencepiece as spm\n",
    "import pandas as pd\n",
    "import time\n",
    "from functools import lru_cache\n",
    "import threading\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_logger(func):\n",
    "  def wrapper(*args, **kwargs):\n",
    "    print(time.strftime(\"%H:%M:%S\",time.localtime()))\n",
    "    func(*args, **kwargs)\n",
    "  return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_progress(filepath):\n",
    "  num_lines = int(0)\n",
    "  try:\n",
    "    with open(filepath,'r', encoding='utf-8') as current_file:\n",
    "      num_lines += int(len(current_file.readlines()))\n",
    "      return num_lines\n",
    "  except:\n",
    "    return int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flush the buffer to the file\n",
    "@time_logger\n",
    "def write_list_to_file(list_to_write, out_filepath):\n",
    "  with open(out_filepath, 'a', encoding='utf-8') as file:\n",
    "    file.writelines([str(x)+\"\\n\" for x in list_to_write])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(encoder, input_text):\n",
    "  return encoder.encode(input_text, out_type=str)\n",
    "\n",
    "def decode(decoder, output_tokens):\n",
    "  return decoder.decode(output_tokens)\n",
    "\n",
    "\n",
    "def translate(model,encoder, decoder, input_text):\n",
    "  input_tokens = encode(encoder, input_text)\n",
    "  output_tokens = model.translate_batch([input_tokens])[0].hypotheses[0]\n",
    "  return decode(decoder, output_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENNMT_MODEL_PATH = 'C:\\\\Users\\\\bijgu\\\\Desktop\\\\Test\\\\bleu_selftrained\\\\en_mt_trans_ct2_20k\\\\'\n",
    "SOURCE_VOCAB_PATH = 'C:\\\\Users\\\\bijgu\\\\Desktop\\\\Test\\\\bleu_selftrained\\\\source.model'\n",
    "TARGET_VOCAB_PATH = 'C:\\\\Users\\\\bijgu\\\\Desktop\\\\Test\\\\bleu_selftrained\\\\target.model'\n",
    "\n",
    "BLEU_ENG_FILEPATH = 'C:\\\\Users\\\\bijgu\\\\Desktop\\\\Test\\\\bleu_selftrained\\\\common.en'\n",
    "BLEU_TRANS_FILEPATH = 'C:\\\\Users\\\\bijgu\\\\Desktop\\\\Test\\\\bleu_selftrained\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time_logger\n",
    "def buffer_translate(input_list, buffer_size, out_filepath):\n",
    "  total_sentences = len(input_list)\n",
    "  translator = ctranslate2.Translator(OPENNMT_MODEL_PATH, device=\"cpu\")\n",
    "  sp1 = spm.SentencePieceProcessor(SOURCE_VOCAB_PATH)\n",
    "  sp2 = spm.SentencePieceProcessor(TARGET_VOCAB_PATH)\n",
    "  \n",
    "  buffers_flushed = 0\n",
    "  buffer_list = []\n",
    "\n",
    "  for sentence in input_list:\n",
    "    buffer_list.append(translate(translator, sp1, sp2, sentence))\n",
    "    if len(buffer_list) >= buffer_size:\n",
    "      write_list_to_file(buffer_list, out_filepath)\n",
    "      buffer_list.clear()\n",
    "      buffers_flushed += 1\n",
    "      print(out_filepath + \": \" + str(int((100*buffers_flushed*buffer_size)/total_sentences)) + \"% complete\")\n",
    "  else:\n",
    "    write_list_to_file(buffer_list, out_filepath)\n",
    "  print(out_filepath + \" DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_text = []\n",
    "with open(BLEU_ENG_FILEPATH,'r',encoding='utf-8') as eng_file:\n",
    "  eng_text = [x.rstrip(\"\\n\") for x in eng_file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1 = eng_text[:2000]\n",
    "batch_2 = eng_text[2000:4000]\n",
    "batch_3 = eng_text[4000:6000]\n",
    "batch_4 = eng_text[6000:8000]\n",
    "batch_5 = eng_text[8000:10000]\n",
    "batch_6 = eng_text[10000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=threading.Thread(target=buffer_translate,args=(batch_1, 200, os.path.join(BLEU_TRANS_FILEPATH,'batch_1.txt')))\n",
    "t2=threading.Thread(target=buffer_translate,args=(batch_2, 200, os.path.join(BLEU_TRANS_FILEPATH,'batch_2.txt')))\n",
    "t3=threading.Thread(target=buffer_translate,args=(batch_3, 200, os.path.join(BLEU_TRANS_FILEPATH,'batch_3.txt')))\n",
    "t4=threading.Thread(target=buffer_translate,args=(batch_4, 200, os.path.join(BLEU_TRANS_FILEPATH,'batch_4.txt')))\n",
    "t5=threading.Thread(target=buffer_translate,args=(batch_5, 200, os.path.join(BLEU_TRANS_FILEPATH,'batch_5.txt')))\n",
    "t6=threading.Thread(target=buffer_translate,args=(batch_6, 200, os.path.join(BLEU_TRANS_FILEPATH,'batch_6.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "t4.start()\n",
    "t5.start()\n",
    "t6.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "t3.join()\n",
    "t4.join()\n",
    "t5.join()\n",
    "t6.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12322"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_file_content(current_list, file):\n",
    "  with open(file, 'r', encoding='utf-8') as i_file:\n",
    "    file_data = [x.strip(\"\\n\") for x in i_file.readlines()]\n",
    "  current_list.extend(file_data)\n",
    "  return current_list\n",
    "\n",
    "list_orig = []\n",
    "\n",
    "file_list = [x for x in os.listdir(BLEU_TRANS_FILEPATH) if x[-4:] == '.txt']\n",
    "file_list = sorted(file_list)\n",
    "\n",
    "for txt_file in file_list:\n",
    "  merge_file_content(list_orig, txt_file)\n",
    "\n",
    "with open('translated_opennmt.mt','w',encoding='utf-8') as o_file:\n",
    "  o_file.writelines([x+\"\\n\" for x in list_orig])\n",
    "\n",
    "len(list_orig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
