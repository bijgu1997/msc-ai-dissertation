{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":910,"status":"ok","timestamp":1698089537627,"user":{"displayName":"Matthew Darmanin","userId":"12311991466692884233"},"user_tz":-120},"id":"Wn4eOIzG2cG4","outputId":"011615bc-7ccb-4bcb-e68a-a8515c4ac428"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/nmt\n","Cloning into 'MT-Preparation'...\n","remote: Enumerating objects: 248, done.\u001b[K\n","remote: Counting objects: 100% (248/248), done.\u001b[K\n","remote: Compressing objects: 100% (139/139), done.\u001b[K\n","remote: Total 248 (delta 123), reused 193 (delta 97), pack-reused 0\u001b[K\n","Receiving objects: 100% (248/248), 64.32 KiB | 9.19 MiB/s, done.\n","Resolving deltas: 100% (123/123), done.\n"]}],"source":["!mkdir -p nmt\n","%cd nmt\n","!git clone https://github.com/ymoslem/MT-Preparation.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5379,"status":"ok","timestamp":1698089543004,"user":{"displayName":"Matthew Darmanin","userId":"12311991466692884233"},"user_tz":-120},"id":"c0iOFjoW2qKv","outputId":"4c6145f4-a12c-4293-ce57-b32d6dd3cf31"},"outputs":[],"source":["!pip3 install -r MT-Preparation/requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11913,"status":"ok","timestamp":1698089554911,"user":{"displayName":"Matthew Darmanin","userId":"12311991466692884233"},"user_tz":-120},"id":"nyvhqcB33SyO","outputId":"05a33885-2642-4a9f-be8a-16e7bb3a32f3"},"outputs":[],"source":["!wget https://object.pouta.csc.fi/OPUS-TildeMODEL/v2018/moses/en-mt.txt.zip\n","!unzip en-mt.txt.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86161,"status":"ok","timestamp":1698089641062,"user":{"displayName":"Matthew Darmanin","userId":"12311991466692884233"},"user_tz":-120},"id":"sBgFhe6_3hbV","outputId":"3a43b300-60f5-447c-a7e6-b0a55044f3d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataframe shape (rows, columns): (1976073, 2)\n","--- Rows with Empty Cells Deleted\t--> Rows: 1976036\n","--- Duplicates Deleted\t\t\t--> Rows: 1964954\n","--- Source-Copied Rows Deleted\t\t--> Rows: 1964013\n","--- Too Long Source/Target Deleted\t--> Rows: 1953464\n","--- HTML Removed\t\t\t--> Rows: 1953464\n","--- Rows will remain in true-cased\t--> Rows: 1953464\n","--- Rows with Empty Cells Deleted\t--> Rows: 1953423\n","--- Rows Shuffled\t\t\t--> Rows: 1953423\n","--- Source Saved: TildeMODEL.en-mt.en-filtered.en\n","--- Target Saved: TildeMODEL.en-mt.mt-filtered.mt\n"]}],"source":["!python3 MT-Preparation/filtering/filter.py TildeMODEL.en-mt.en TildeMODEL.en-mt.mt en mt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1698089641062,"user":{"displayName":"Matthew Darmanin","userId":"12311991466692884233"},"user_tz":-120},"id":"Kplkp4jU4Um1","outputId":"dfa30eef-9002-4fbe-e287-dd4ef77e6b65"},"outputs":[{"name":"stdout","output_type":"stream","text":["1-train_bpe.py\t1-train_unigram.py  2-subword.py  3-desubword.py\n"]}],"source":["!ls MT-Preparation/subwording/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":458107,"status":"ok","timestamp":1698090099167,"user":{"displayName":"Matthew Darmanin","userId":"12311991466692884233"},"user_tz":-120},"id":"Mb90_7aw4Wbv","outputId":"17c9779b-15a1-4b0b-aa92-deaa3fdcbf90"},"outputs":[{"name":"stdout","output_type":"stream","text":["sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=TildeMODEL.en-mt.en-filtered.en --model_prefix=source --vocab_size=50000 --hard_vocab_limit=false --split_digits=true\n","sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n","trainer_spec {\n","  input: TildeMODEL.en-mt.en-filtered.en\n","  input_format: \n","  model_prefix: source\n","  model_type: UNIGRAM\n","  vocab_size: 50000\n","  self_test_sample_size: 0\n","  character_coverage: 0.9995\n","  input_sentence_size: 0\n","  shuffle_input_sentence: 1\n","  seed_sentencepiece_size: 1000000\n","  shrinking_factor: 0.75\n","  max_sentence_length: 4192\n","  num_threads: 16\n","  num_sub_iterations: 2\n","  max_sentencepiece_length: 16\n","  split_by_unicode_script: 1\n","  split_by_number: 1\n","  split_by_whitespace: 1\n","  split_digits: 1\n","  pretokenization_delimiter: \n","  treat_whitespace_as_suffix: 0\n","  allow_whitespace_only_pieces: 0\n","  required_chars: \n","  byte_fallback: 0\n","  vocabulary_output_piece_score: 1\n","  train_extremely_large_corpus: 0\n","  hard_vocab_limit: 0\n","  use_all_vocab: 0\n","  unk_id: 0\n","  bos_id: 1\n","  eos_id: 2\n","  pad_id: -1\n","  unk_piece: <unk>\n","  bos_piece: <s>\n","  eos_piece: </s>\n","  pad_piece: <pad>\n","  unk_surface:  ⁇ \n","  enable_differential_privacy: 0\n","  differential_privacy_noise_level: 0\n","  differential_privacy_clipping_threshold: 0\n","}\n","normalizer_spec {\n","  name: nmt_nfkc\n","  add_dummy_prefix: 1\n","  remove_extra_whitespaces: 1\n","  escape_whitespaces: 1\n","  normalization_rule_tsv: \n","}\n","denormalizer_spec {}\n","trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n","trainer_interface.cc(183) LOG(INFO) Loading corpus: TildeMODEL.en-mt.en-filtered.en\n","trainer_interface.cc(145) LOG(INFO) Loaded 1000000 lines\n","trainer_interface.cc(122) LOG(WARNING) Too many sentences are loaded! (1953423), which may slow down training.\n","trainer_interface.cc(124) LOG(WARNING) Consider using --input_sentence_size=<size> and --shuffle_input_sentence=true.\n","trainer_interface.cc(127) LOG(WARNING) They allow to randomly sample <size> sentences from the entire corpus.\n","trainer_interface.cc(407) LOG(INFO) Loaded all 1953423 sentences\n","trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n","trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n","trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n","trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n","trainer_interface.cc(537) LOG(INFO) all chars count=263341728\n","trainer_interface.cc(548) LOG(INFO) Done: 99.9515% characters are covered.\n","trainer_interface.cc(558) LOG(INFO) Alphabet size=82\n","trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999515\n","trainer_interface.cc(591) LOG(INFO) Done! preprocessed 1953423 sentences.\n","unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n","unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=151524074\n","unigram_model_trainer.cc(274) LOG(INFO) Initialized 337723 seed sentencepieces\n","trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 1953423\n","trainer_interface.cc(608) LOG(INFO) Done! 559734\n","unigram_model_trainer.cc(564) LOG(INFO) Using 559734 sentences for EM training\n","unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=138919 obj=11.7397 num_tokens=2080995 num_tokens/piece=14.9799\n","unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=115133 obj=8.71056 num_tokens=2085791 num_tokens/piece=18.1164\n","unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=86343 obj=8.68876 num_tokens=2120291 num_tokens/piece=24.5566\n","unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=86317 obj=8.68634 num_tokens=2123791 num_tokens/piece=24.6046\n","unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=64736 obj=8.70701 num_tokens=2179580 num_tokens/piece=33.6687\n","unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=64736 obj=8.70326 num_tokens=2179470 num_tokens/piece=33.667\n","unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=55000 obj=8.71646 num_tokens=2214938 num_tokens/piece=40.2716\n","unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=55000 obj=8.71426 num_tokens=2214883 num_tokens/piece=40.2706\n","trainer_interface.cc(686) LOG(INFO) Saving model: source.model\n","trainer_interface.cc(698) LOG(INFO) Saving vocabs: source.vocab\n","Done, training a SentencepPiece model for the Source finished successfully!\n","sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=TildeMODEL.en-mt.mt-filtered.mt --model_prefix=target --vocab_size=50000 --hard_vocab_limit=false --split_digits=true\n","sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n","trainer_spec {\n","  input: TildeMODEL.en-mt.mt-filtered.mt\n","  input_format: \n","  model_prefix: target\n","  model_type: UNIGRAM\n","  vocab_size: 50000\n","  self_test_sample_size: 0\n","  character_coverage: 0.9995\n","  input_sentence_size: 0\n","  shuffle_input_sentence: 1\n","  seed_sentencepiece_size: 1000000\n","  shrinking_factor: 0.75\n","  max_sentence_length: 4192\n","  num_threads: 16\n","  num_sub_iterations: 2\n","  max_sentencepiece_length: 16\n","  split_by_unicode_script: 1\n","  split_by_number: 1\n","  split_by_whitespace: 1\n","  split_digits: 1\n","  pretokenization_delimiter: \n","  treat_whitespace_as_suffix: 0\n","  allow_whitespace_only_pieces: 0\n","  required_chars: \n","  byte_fallback: 0\n","  vocabulary_output_piece_score: 1\n","  train_extremely_large_corpus: 0\n","  hard_vocab_limit: 0\n","  use_all_vocab: 0\n","  unk_id: 0\n","  bos_id: 1\n","  eos_id: 2\n","  pad_id: -1\n","  unk_piece: <unk>\n","  bos_piece: <s>\n","  eos_piece: </s>\n","  pad_piece: <pad>\n","  unk_surface:  ⁇ \n","  enable_differential_privacy: 0\n","  differential_privacy_noise_level: 0\n","  differential_privacy_clipping_threshold: 0\n","}\n","normalizer_spec {\n","  name: nmt_nfkc\n","  add_dummy_prefix: 1\n","  remove_extra_whitespaces: 1\n","  escape_whitespaces: 1\n","  normalization_rule_tsv: \n","}\n","denormalizer_spec {}\n","trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n","trainer_interface.cc(183) LOG(INFO) Loading corpus: TildeMODEL.en-mt.mt-filtered.mt\n","trainer_interface.cc(145) LOG(INFO) Loaded 1000000 lines\n","trainer_interface.cc(122) LOG(WARNING) Too many sentences are loaded! (1953423), which may slow down training.\n","trainer_interface.cc(124) LOG(WARNING) Consider using --input_sentence_size=<size> and --shuffle_input_sentence=true.\n","trainer_interface.cc(127) LOG(WARNING) They allow to randomly sample <size> sentences from the entire corpus.\n","trainer_interface.cc(407) LOG(INFO) Loaded all 1953423 sentences\n","trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n","trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n","trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n","trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n","trainer_interface.cc(537) LOG(INFO) all chars count=289789230\n","trainer_interface.cc(548) LOG(INFO) Done: 99.9521% characters are covered.\n","trainer_interface.cc(558) LOG(INFO) Alphabet size=91\n","trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999521\n","trainer_interface.cc(591) LOG(INFO) Done! preprocessed 1953423 sentences.\n","unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n","unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=169178107\n","unigram_model_trainer.cc(274) LOG(INFO) Initialized 598455 seed sentencepieces\n","trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 1953423\n","trainer_interface.cc(608) LOG(INFO) Done! 983382\n","unigram_model_trainer.cc(564) LOG(INFO) Using 983382 sentences for EM training\n","unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=230785 obj=17.0002 num_tokens=3591549 num_tokens/piece=15.5623\n","unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=198232 obj=12.206 num_tokens=3601077 num_tokens/piece=18.166\n","unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=148654 obj=12.1815 num_tokens=3652174 num_tokens/piece=24.5683\n","unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=148583 obj=12.1761 num_tokens=3655970 num_tokens/piece=24.6056\n","unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=111434 obj=12.2051 num_tokens=3739851 num_tokens/piece=33.5611\n","unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=111434 obj=12.1999 num_tokens=3739748 num_tokens/piece=33.5602\n","unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=83574 obj=12.2391 num_tokens=3839563 num_tokens/piece=45.9421\n","unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=83574 obj=12.2318 num_tokens=3839367 num_tokens/piece=45.9397\n","unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=62680 obj=12.2945 num_tokens=3951317 num_tokens/piece=63.0395\n","unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=62680 obj=12.2843 num_tokens=3951054 num_tokens/piece=63.0353\n","unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=55000 obj=12.3166 num_tokens=4002844 num_tokens/piece=72.779\n","unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=55000 obj=12.3131 num_tokens=4002803 num_tokens/piece=72.7782\n","trainer_interface.cc(686) LOG(INFO) Saving model: target.model\n","trainer_interface.cc(698) LOG(INFO) Saving vocabs: target.vocab\n","Done, training a SentencepPiece model for the Target finished successfully!\n"]}],"source":["# Train a SentencePiece model for subword tokenization\n","!python3 MT-Preparation/subwording/1-train_unigram.py TildeMODEL.en-mt.en-filtered.en TildeMODEL.en-mt.mt-filtered.mt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1698090099167,"user":{"displayName":"Matthew Darmanin","userId":"12311991466692884233"},"user_tz":-120},"id":"splpUJy37s4l","outputId":"8a476e2a-bcf7-4760-ae3f-a3195c466360"},"outputs":[{"name":"stdout","output_type":"stream","text":["en-mt.txt.zip\tsource.model  TildeMODEL.en-mt.en\t       TildeMODEL.en-mt.xml\n","LICENSE\t\tsource.vocab  TildeMODEL.en-mt.en-filtered.en\n","MT-Preparation\ttarget.model  TildeMODEL.en-mt.mt\n","README\t\ttarget.vocab  TildeMODEL.en-mt.mt-filtered.mt\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":157635,"status":"ok","timestamp":1698090256800,"user":{"displayName":"Matthew Darmanin","userId":"12311991466692884233"},"user_tz":-120},"id":"RteujJdv7sFi","outputId":"6cf616bb-34e6-4ca2-aeed-a41532ebbe82"},"outputs":[{"name":"stdout","output_type":"stream","text":["Source Model: source.model\n","Target Model: target.model\n","Source Dataset: TildeMODEL.en-mt.en-filtered.en\n","Target Dataset: TildeMODEL.en-mt.mt-filtered.mt\n","Done subwording the source file! Output: TildeMODEL.en-mt.en-filtered.en.subword\n","Done subwording the target file! Output: TildeMODEL.en-mt.mt-filtered.mt.subword\n"]}],"source":["# Subword the dataset\n","!python3 MT-Preparation/subwording/2-subword.py source.model target.model TildeMODEL.en-mt.en-filtered.en TildeMODEL.en-mt.mt-filtered.mt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1698090256801,"user":{"displayName":"Matthew Darmanin","userId":"12311991466692884233"},"user_tz":-120},"id":"6neOqAM18ARF","outputId":"f33e0567-f2b7-462c-9403-a033a2c9c591"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ambrisentan is highly plasma protein bound.\n","It is vital to eliminate any remaining obstacles on this front.\n","Reforming Europe for the 21st Century\n","-----\n","Ambrisentan jintrabat ħafna mal-proteini tal-plażma.\n","Xi ostakoli li għadhom jeżistu f’dan il-qasam iridu jitneħħew.\n","Nirriformaw l-Ewropa għas-Seklu 21\n"]}],"source":["!head -n 3 TildeMODEL.en-mt.en-filtered.en && echo \"-----\" && head -n 3 TildeMODEL.en-mt.mt-filtered.mt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1698090256801,"user":{"displayName":"Matthew Darmanin","userId":"12311991466692884233"},"user_tz":-120},"id":"Oo4bxoZ18H3C","outputId":"2960e918-bb6c-4cb1-ee0c-ac9d40ef025d"},"outputs":[{"name":"stdout","output_type":"stream","text":["▁A mbrisentan ▁is ▁highly ▁plasma ▁protein ▁bound .\n","▁It ▁is ▁vital ▁to ▁eliminate ▁any ▁remaining ▁obstacles ▁on ▁this ▁front .\n","▁Reforming ▁Europe ▁for ▁the ▁ 2 1 st ▁Century\n","-----\n","▁Ambrisentan ▁jintrabat ▁ħafna ▁mal - proteini ▁tal - plażma .\n","▁Xi ▁ostakoli ▁li ▁għadhom ▁jeżistu ▁f ’ dan ▁il - qasam ▁iridu ▁jitneħħew .\n","▁N ir riforma w ▁l - Ewropa ▁għas - Seklu ▁ 2 1\n"]}],"source":["!head -n 3 TildeMODEL.en-mt.en-filtered.en.subword && echo \"-----\" && head -n 3 TildeMODEL.en-mt.mt-filtered.mt.subword"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25504,"status":"ok","timestamp":1698090282302,"user":{"displayName":"Matthew Darmanin","userId":"12311991466692884233"},"user_tz":-120},"id":"QxYoqWN69o7U","outputId":"2edc4e08-5e75-4cef-a968-f33b6de32d4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataframe shape: (1953423, 2)\n","--- Empty Cells Deleted --> Rows: 1953423\n","--- Wrote Files\n","Done!\n","Output files\n","TildeMODEL.en-mt.en-filtered.en.subword.train\n","TildeMODEL.en-mt.mt-filtered.mt.subword.train\n","TildeMODEL.en-mt.en-filtered.en.subword.dev\n","TildeMODEL.en-mt.mt-filtered.mt.subword.dev\n","TildeMODEL.en-mt.en-filtered.en.subword.test\n","TildeMODEL.en-mt.mt-filtered.mt.subword.test\n"]}],"source":["!python3 MT-Preparation/train_dev_split/train_dev_test_split.py 2000 2000 TildeMODEL.en-mt.en-filtered.en.subword TildeMODEL.en-mt.mt-filtered.mt.subword"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":905,"status":"ok","timestamp":1698090283197,"user":{"displayName":"Matthew Darmanin","userId":"12311991466692884233"},"user_tz":-120},"id":"pDUhSuNs95Ue","outputId":"e13f0e75-1d9f-4f20-c5c0-b28aa8227413"},"outputs":[{"name":"stdout","output_type":"stream","text":["     2000 TildeMODEL.en-mt.en-filtered.en.subword.dev\n","     2000 TildeMODEL.en-mt.en-filtered.en.subword.test\n","  1949423 TildeMODEL.en-mt.en-filtered.en.subword.train\n","     2000 TildeMODEL.en-mt.mt-filtered.mt.subword.dev\n","     2000 TildeMODEL.en-mt.mt-filtered.mt.subword.test\n","  1949423 TildeMODEL.en-mt.mt-filtered.mt.subword.train\n","  3906846 total\n"]}],"source":["!wc -l *.subword.*"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1698090283197,"user":{"displayName":"Matthew Darmanin","userId":"12311991466692884233"},"user_tz":-120},"id":"a0gQoHXd989L","outputId":"da233d10-7889-46e0-a01a-17346f578b86"},"outputs":[{"name":"stdout","output_type":"stream","text":["My name is: Matthew Darmanin \n","\n","---First line---\n","==> TildeMODEL.en-mt.en-filtered.en.subword.train <==\n","▁A mbrisentan ▁is ▁highly ▁plasma ▁protein ▁bound .\n","\n","==> TildeMODEL.en-mt.mt-filtered.mt.subword.train <==\n","▁Ambrisentan ▁jintrabat ▁ħafna ▁mal - proteini ▁tal - plażma .\n","\n","==> TildeMODEL.en-mt.en-filtered.en.subword.dev <==\n","▁After ▁ 6 0 ▁months ▁of ▁follow - up , ▁median ▁time ▁to ▁cCCyR ▁was ▁ 3 . 1 ▁months ▁in ▁the ▁SPRYCEL ▁group ▁and\n","\n","==> TildeMODEL.en-mt.mt-filtered.mt.subword.dev <==\n","▁Wara ▁ 6 0 ▁xahar ▁ta ’ ▁follow - up , ▁iż - żmien ▁medjan ▁għal ▁c CCyR ▁kien ▁ta ’ ▁ 3 . 1 ▁xhur ▁fil - grupp ▁ta ’ ▁SPRYCEL ▁u\n","\n","==> TildeMODEL.en-mt.en-filtered.en.subword.test <==\n","▁It ▁is ▁also ▁recommended ▁that ▁corresponding ▁targets ▁be ▁written ▁into ▁national ▁reform ▁programmes .\n","\n","==> TildeMODEL.en-mt.mt-filtered.mt.subword.test <==\n","▁Il - KESE ▁jħeġġeġ ▁ukoll ▁li ▁dawn ▁l - għanijiet ▁jitniżżlu ▁fil - Programmi ▁Nazzjonali ▁ta ’ ▁Riforma .\n","\n","---Last line---\n","==> TildeMODEL.en-mt.en-filtered.en.subword.train <==\n","▁Accession ▁Countries\n","\n","==> TildeMODEL.en-mt.mt-filtered.mt.subword.train <==\n","▁Pajjiżi ▁ta ' ▁Adeżjoni\n","\n","==> TildeMODEL.en-mt.en-filtered.en.subword.dev <==\n","▁AMEND ING ▁THE ▁AGREEMENT\n","\n","==> TildeMODEL.en-mt.mt-filtered.mt.subword.dev <==\n","▁LI ▁J EMEND A ▁L - FTEHIM\n","\n","==> TildeMODEL.en-mt.en-filtered.en.subword.test <==\n","▁How ▁is ▁BeneFIX ▁used ?\n","\n","==> TildeMODEL.en-mt.mt-filtered.mt.subword.test <==\n","▁Kif ▁jintuża ▁BeneFIX ?\n"]}],"source":["# Check the first and last line from each dataset\n","\n","# -------------------------------------------\n","# Change this cell to print your name\n","!echo -e \"My name is: Matthew Darmanin \\n\"\n","# -------------------------------------------\n","\n","!echo \"---First line---\"\n","!head -n 1 *.{train,dev,test}\n","\n","!echo -e \"\\n---Last line---\"\n","!tail -n 1 *.{train,dev,test}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yU9zWA86-KWz"},"outputs":[],"source":["!cp -R /content/nmt/ /content/drive/MyDrive/Dissertation/NMT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25618,"status":"ok","timestamp":1698090322962,"user":{"displayName":"Matthew Darmanin","userId":"12311991466692884233"},"user_tz":-120},"id":"mLfiWcVk_vbj","outputId":"25336e11-6d09-41c4-f904-e4bd58119e6e"},"outputs":[],"source":["!pip3 install OpenNMT-py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1698090322962,"user":{"displayName":"Matthew Darmanin","userId":"12311991466692884233"},"user_tz":-120},"id":"pGcuSWdr_yQj","outputId":"31071b0a-9947-42ea-eddd-ee887ff5928d"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Dissertation/NMT/nmt\n"]}],"source":["%cd /content/drive/MyDrive/Dissertation/NMT/nmt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1698090322962,"user":{"displayName":"Matthew Darmanin","userId":"12311991466692884233"},"user_tz":-120},"id":"SW5TVv0g_4BO","outputId":"297b91d6-f615-42d3-f7ff-b287052b0f96"},"outputs":[{"name":"stdout","output_type":"stream","text":["en-mt.txt.zip\t\t\t\t TildeMODEL.en-mt.en-filtered.en.subword.dev\n","LICENSE\t\t\t\t\t TildeMODEL.en-mt.en-filtered.en.subword.test\n","MT-Preparation\t\t\t\t TildeMODEL.en-mt.en-filtered.en.subword.train\n","README\t\t\t\t\t TildeMODEL.en-mt.mt\n","source.model\t\t\t\t TildeMODEL.en-mt.mt-filtered.mt\n","source.vocab\t\t\t\t TildeMODEL.en-mt.mt-filtered.mt.subword\n","target.model\t\t\t\t TildeMODEL.en-mt.mt-filtered.mt.subword.dev\n","target.vocab\t\t\t\t TildeMODEL.en-mt.mt-filtered.mt.subword.test\n","TildeMODEL.en-mt.en\t\t\t TildeMODEL.en-mt.mt-filtered.mt.subword.train\n","TildeMODEL.en-mt.en-filtered.en\t\t TildeMODEL.en-mt.xml\n","TildeMODEL.en-mt.en-filtered.en.subword\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kNymTt0e-wR6"},"outputs":[],"source":["# Create the YAML configuration file\n","# On a regular machine, you can create it manually or with nano\n","# Note here we are using some smaller values because the dataset is small\n","# For larger datasets, consider increasing: train_steps, valid_steps, warmup_steps, save_checkpoint_steps, keep_checkpoint\n","\n","config = '''# config.yaml\n","\n","\n","## Where the samples will be written\n","save_data: run\n","\n","# Training files\n","data:\n","    corpus_1:\n","        path_src: TildeMODEL.en-mt.en-filtered.en.subword.train\n","        path_tgt: TildeMODEL.en-mt.mt-filtered.mt.subword.train\n","        transforms: [filtertoolong]\n","    valid:\n","        path_src: TildeMODEL.en-mt.en-filtered.en.subword.dev\n","        path_tgt: TildeMODEL.en-mt.mt-filtered.mt.subword.dev\n","        transforms: [filtertoolong]\n","\n","# Vocabulary files, generated by onmt_build_vocab\n","src_vocab: run/source.vocab\n","tgt_vocab: run/target.vocab\n","\n","# Vocabulary size - should be the same as in sentence piece\n","src_vocab_size: 50000\n","tgt_vocab_size: 50000\n","\n","# Filter out source/target longer than n if [filtertoolong] enabled\n","src_seq_length: 150\n","src_seq_length: 150\n","\n","# Tokenization options\n","src_subword_model: source.model\n","tgt_subword_model: target.model\n","\n","# Where to save the log file and the output models/checkpoints\n","log_file: train.log\n","save_model: models/model.fren\n","\n","# Stop training if it does not imporve after n validations\n","early_stopping: 4\n","\n","# Default: 5000 - Save a model checkpoint for each n\n","save_checkpoint_steps: 1000\n","\n","# To save space, limit checkpoints to last n\n","# keep_checkpoint: 3\n","\n","seed: 3435\n","\n","# Default: 100000 - Train the model to max n steps\n","# Increase to 200000 or more for large datasets\n","# For fine-tuning, add up the required steps to the original steps\n","train_steps: 150000\n","\n","# Default: 10000 - Run validation after n steps\n","valid_steps: 5000\n","\n","# Default: 4000 - for large datasets, try up to 8000\n","warmup_steps: 4000\n","report_every: 100\n","\n","# Number of GPUs, and IDs of GPUs\n","world_size: 1\n","gpu_ranks: [0]\n","\n","# Batching\n","bucket_size: 262144\n","num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n","batch_type: \"tokens\"\n","batch_size: 4096   # Tokens per batch, change when CUDA out of memory\n","valid_batch_size: 2048\n","max_generator_batches: 2\n","accum_count: [4]\n","accum_steps: [0]\n","\n","# Optimization\n","model_dtype: \"fp16\"\n","optim: \"adam\"\n","learning_rate: 2\n","# warmup_steps: 8000\n","decay_method: \"noam\"\n","adam_beta2: 0.998\n","max_grad_norm: 0\n","label_smoothing: 0.1\n","param_init: 0\n","param_init_glorot: true\n","normalization: \"tokens\"\n","\n","# Model\n","encoder_type: transformer\n","decoder_type: transformer\n","position_encoding: true\n","enc_layers: 6\n","dec_layers: 6\n","heads: 8\n","hidden_size: 512\n","word_vec_size: 512\n","transformer_ff: 2048\n","dropout_steps: [0]\n","dropout: [0.1]\n","attention_dropout: [0.1]\n","'''\n","\n","with open(\"config.yaml\", \"w+\") as config_yaml:\n","  config_yaml.write(config)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1698090322962,"user":{"displayName":"Matthew Darmanin","userId":"12311991466692884233"},"user_tz":-120},"id":"2Ib__2GE_Xyg","outputId":"251258ac-78a2-42cf-f00b-3f00428471cd"},"outputs":[{"name":"stdout","output_type":"stream","text":["2\n"]}],"source":["# Find the number of CPUs/cores on the machine\n","!nproc --all"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":99006,"status":"ok","timestamp":1698090421963,"user":{"displayName":"Matthew Darmanin","userId":"12311991466692884233"},"user_tz":-120},"id":"ez0SFuXo_dHL","outputId":"ef02debb-260f-4ad1-8fb0-772a714ad641"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-10-23 19:45:27.758863: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-10-23 19:45:27.758937: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-10-23 19:45:27.758984: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-10-23 19:45:27.765500: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-10-23 19:45:29.035222: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Corpus corpus_1's weight should be given. We default it to 1 for you.\n","[2023-10-23 19:45:32,633 INFO] Counter vocab from -1 samples.\n","[2023-10-23 19:45:32,633 INFO] n_sample=-1: Build vocab on full datasets.\n","[2023-10-23 19:46:58,061 INFO] * Transform statistics for corpus_1(50.00%):\n","\t\t\t* FilterTooLongStats(filtered=872)\n","\n","[2023-10-23 19:46:58,263 INFO] * Transform statistics for corpus_1(50.00%):\n","\t\t\t* FilterTooLongStats(filtered=839)\n","\n","[2023-10-23 19:46:58,440 INFO] Counters src: 50945\n","[2023-10-23 19:46:58,440 INFO] Counters tgt: 50984\n"]}],"source":["# Build Vocabulary\n","\n","# -config: path to your config.yaml file\n","# -n_sample: use -1 to build vocabulary on all the segment in the training dataset\n","# -num_threads: change it to match the number of CPUs to run it faster\n","\n","!onmt_build_vocab -config config.yaml -n_sample -1 -num_threads 2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":282,"status":"ok","timestamp":1698090614625,"user":{"displayName":"Matthew Darmanin","userId":"12311991466692884233"},"user_tz":-120},"id":"mKu8JtJvAspG","outputId":"82605283-6acb-4260-c6de-658241d13686"},"outputs":[{"name":"stdout","output_type":"stream","text":["GPU 0: Tesla T4 (UUID: GPU-9db1f03d-f398-74ba-74df-36a4686d36fa)\n"]}],"source":["!nvidia-smi -L"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3725,"status":"ok","timestamp":1698090620508,"user":{"displayName":"Matthew Darmanin","userId":"12311991466692884233"},"user_tz":-120},"id":"_KhTP-ZJA0te","outputId":"9b0c89bf-c9db-4ba9-ce9b-7ac5754c8513"},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n","Tesla T4\n","Free GPU memory: 14998.8125 out of: 15101.8125\n"]}],"source":["import torch\n","\n","print(torch.cuda.is_available())\n","print(torch.cuda.get_device_name(0))\n","\n","gpu_memory = torch.cuda.mem_get_info(0)\n","print(\"Free GPU memory:\", gpu_memory[0]/1024**2, \"out of:\", gpu_memory[1]/1024**2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iapbKGFfBD2V"},"outputs":[],"source":["!rm -rf drive/MyDrive/Dissertation/NMT/nmt/models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":318,"status":"ok","timestamp":1698091063642,"user":{"displayName":"Matthew Darmanin","userId":"12311991466692884233"},"user_tz":-120},"id":"HDggAMjcBLsu","outputId":"a8908268-fd64-45bd-b380-4f08798179da"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Errno 2] No such file or directory: 'drive/MyDrive/Dissertation/NMT/'\n","/content/drive/MyDrive/Dissertation/NMT/nmt\n","config.yaml\t\t\t TildeMODEL.en-mt.en-filtered.en.subword\n","en-mt.txt.zip\t\t\t TildeMODEL.en-mt.en-filtered.en.subword.dev\n","LICENSE\t\t\t\t TildeMODEL.en-mt.en-filtered.en.subword.test\n","MT-Preparation\t\t\t TildeMODEL.en-mt.en-filtered.en.subword.train\n","README\t\t\t\t TildeMODEL.en-mt.mt\n","run\t\t\t\t TildeMODEL.en-mt.mt-filtered.mt\n","source.model\t\t\t TildeMODEL.en-mt.mt-filtered.mt.subword\n","source.vocab\t\t\t TildeMODEL.en-mt.mt-filtered.mt.subword.dev\n","target.model\t\t\t TildeMODEL.en-mt.mt-filtered.mt.subword.test\n","target.vocab\t\t\t TildeMODEL.en-mt.mt-filtered.mt.subword.train\n","TildeMODEL.en-mt.en\t\t TildeMODEL.en-mt.xml\n","TildeMODEL.en-mt.en-filtered.en\n"]}],"source":["%cd drive/MyDrive/Dissertation/NMT/\n","!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":280,"status":"ok","timestamp":1698090928373,"user":{"displayName":"Matthew Darmanin","userId":"12311991466692884233"},"user_tz":-120},"id":"iL-Tcnt7BG9r","outputId":"ad18c979-792b-415e-96e4-3dd4d8cf4c76"},"outputs":[],"source":["!onmt_train -config config.yaml"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNWv5uMh8KtScSvtURZvUfl","gpuType":"T4","mount_file_id":"18bP7F33caQmhSFZnimBB03lh3P-csTUr","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
